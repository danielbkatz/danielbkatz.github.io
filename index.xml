<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Daniel Katz on Daniel Katz</title>
    <link>/</link>
    <description>Recent content in Daniel Katz on Daniel Katz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Tutorial</title>
      <link>/tutorial/</link>
      <pubDate>Fri, 15 Mar 2019 18:23:21 -0700</pubDate>
      
      <guid>/tutorial/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Correlation Doesn&#39;t Even Imply ... Correlation, Necessarily</title>
      <link>/post/correlation-doesn-t-even-imply-a-relationship-necessarily/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/correlation-doesn-t-even-imply-a-relationship-necessarily/</guid>
      <description>


&lt;p&gt;There’s a problem with the various versions of the oft-heard-in-intro-stats-courses phrase “correlation does not imply causation.” It gives early statistics students the wrong impressions.&lt;/p&gt;
&lt;p&gt;The idea seems simple: Just because there is statistical correlation in the data present does not mean that that there is a real world causal relationship (a complicated term, it turns out) between x and y. You know, x could have a high correlation with y but actually, w is simply a mutual cause of x and y. Or something like that.&lt;/p&gt;
&lt;p&gt;The phrase is problematic because it’s actually not accurate.&lt;/p&gt;
&lt;p&gt;1.) The first problem is that the only thing that may indicate a causal relationship statistically is correlation. The more accurate phrase might be something like, “correlation does not &lt;strong&gt;&lt;em&gt;necessarily&lt;/em&gt;&lt;/strong&gt; imply causation”&lt;/p&gt;
&lt;p&gt;2.) The next problem is that, paradoxically, the phrase does not go far enough. Correlaion present in data does not even indicate a real world relationship, let alone a causal one!&lt;/p&gt;
&lt;p&gt;Point 2 can be demonstrated. We’ll generate completely random distributions and then correlate them. Then we’ll do this over and over and look at how the correlations values vary.&lt;/p&gt;
&lt;div id=&#34;correlating-the-uncorrelated&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Correlating the Uncorrelated&lt;/h3&gt;
&lt;p&gt;Let’s start by generating two random normal distributions of size 20, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is 0, &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is 1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
dist1 &amp;lt;- rnorm(20)
dist2 &amp;lt;- rnorm(20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These two distributions, aside from being generated on my computer, have nothing to do with each other and represent nothing in the real world. If you have no interest in the R code, that’s fine, just pay attention to the fact that we’re working with random distributions that have no real world relationship.&lt;/p&gt;
&lt;p&gt;We can correlate them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(dist1, dist2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.09172278&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Correlation is -.09, not very large.&lt;/p&gt;
&lt;p&gt;Let’s do this again.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(9201989)
dista &amp;lt;- rnorm(20)

distb &amp;lt;- rnorm(20)

cor(dista, distb)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.3213314&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hm, -.32, we’re starting to get somewhere. But they’re random numbers. Let’s say we do this over and over again and graph the correlation coefficients. I created a function to do this as an exhibit.&lt;/p&gt;
&lt;p&gt;It takes as input, the number of times to replicate creating the distribrutions of size &lt;em&gt;samples&lt;/em&gt; and a particular correlation value, or &lt;em&gt;cor.cutoff&lt;/em&gt;. The function returns the number of times a correlation value above this cutoff (cor.cutoff) is returned.&lt;/p&gt;
&lt;p&gt;The code is below. It returns a list. Element 1 is the number of times a correlation value at least as large as cor.cutoff is returned. Element 2 is a line plot of correlation coefficients. Each replication returns one correlation coefficient. And the third element in the returned list is a dataframe containing each correlation coefficient for each replication.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

totfunc &amp;lt;- function(reps, samples, cor.cutoff){
random &amp;lt;- function(samples){
  dist1 &amp;lt;- rnorm(samples, 0, 1)
  dist2 &amp;lt;- rnorm(samples, 0, 1)
distab &amp;lt;- as.data.frame(cbind(dist1, dist2))
x1 &amp;lt;- cor(dist1, dist2)}


test1 &amp;lt;-replicate(reps, random(samples))

test2 &amp;lt;- as.data.frame(cbind(test1, c(1:reps)))

corpl &amp;lt;- ggplot(data = test2, aes(x=V2, y = test1)) + geom_line() + xlab(&amp;quot;Replication Number&amp;quot;) + ylab(&amp;quot;Pearson&amp;#39;s Correlation Coeffient Value&amp;quot;)
x2 &amp;lt;- sum(test2$test1 &amp;gt;= cor.cutoff)

corpl
plotsr &amp;lt;- list(x2, corpl, test2)
return(plotsr)
} &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see how this works. We’ll start with distributions of size 20 and correlate them. We’ll repeat this process 1000 times. we want to know how many correlation coefficients above the absolute value of .6 exist.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(23)
testtot &amp;lt;- totfunc(1000, 20, abs(.6))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see the plot of correlation coefficients:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testtot[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-12-correlation-doesn-t-even-imply-a-relationship-necessarily_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not the pretties, but you get the idea. Correlation values are all over the place. How many times does the correlation value exceed the absolute value of .6?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testtot[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yep, 5 times. That’s fairly impressive. We were able to generate two random distributions, and depending on the sample, got correlation values that exceeded .6.&lt;/p&gt;
&lt;p&gt;If you want to understand why a correlation coefficient doesn’t necessarily describe a real world relationship, this is why!&lt;/p&gt;
&lt;p&gt;And if you want to play with some other numbers, say, with random distributions of size 1000 and do it a thousand times, we can.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test2 &amp;lt;- totfunc(1000, 1000, abs(.6))

test2[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test2[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-12-correlation-doesn-t-even-imply-a-relationship-necessarily_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello R Markdown</title>
      <link>/post/2015-07-23-r-rmarkdown/</link>
      <pubDate>Thu, 23 Jul 2015 21:13:14 -0500</pubDate>
      
      <guid>/post/2015-07-23-r-rmarkdown/</guid>
      <description>


&lt;div id=&#34;r-markdown&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R Markdown&lt;/h1&gt;
&lt;p&gt;This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see &lt;a href=&#34;http://rmarkdown.rstudio.com&#34; class=&#34;uri&#34;&gt;http://rmarkdown.rstudio.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can embed an R code chunk like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(cars)
##      speed           dist       
##  Min.   : 4.0   Min.   :  2.00  
##  1st Qu.:12.0   1st Qu.: 26.00  
##  Median :15.0   Median : 36.00  
##  Mean   :15.4   Mean   : 42.98  
##  3rd Qu.:19.0   3rd Qu.: 56.00  
##  Max.   :25.0   Max.   :120.00
fit &amp;lt;- lm(dist ~ speed, data = cars)
fit
## 
## Call:
## lm(formula = dist ~ speed, data = cars)
## 
## Coefficients:
## (Intercept)        speed  
##     -17.579        3.932&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;including-plots&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Including Plots&lt;/h1&gt;
&lt;p&gt;You can also embed plots. See Figure &lt;a href=&#34;#fig:pie&#34;&gt;1&lt;/a&gt; for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mar = c(0, 1, 0, 1))
pie(
  c(280, 60, 20),
  c(&amp;#39;Sky&amp;#39;, &amp;#39;Sunny side of pyramid&amp;#39;, &amp;#39;Shady side of pyramid&amp;#39;),
  col = c(&amp;#39;#0292D8&amp;#39;, &amp;#39;#F7EA39&amp;#39;, &amp;#39;#C4B632&amp;#39;),
  init.angle = -50, border = NA
)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:pie&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/post/2015-07-23-r-rmarkdown_files/figure-html/pie-1.png&#34; alt=&#34;A fancy pie chart.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A fancy pie chart.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/tutorial/explanatoryirt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/tutorial/explanatoryirt/</guid>
      <description>


&lt;table style=&#34;width:4%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;title: “Explanatory IRT tutorial with the TAM package in R” output: html_document: default linktitle = “Explanatory IRT”&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;date = 2018-09-09T00:00:00 # lastmod = 2018-09-09T00:00:00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;draft = false # Is this a draft? true/false toc = true # Show table of contents? true/false type = “docs” # Do not modify.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;# Add menu entry to sidebar. [menu.tutorial] parent = “Explanatory IRT” weight = 1 +++&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;## Get the Data Read in First, I want to make sure everybody gets the data read into R in the exact same way.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;```r #install packages to get data #install.packages(“tidyverse”) #install.packages(“TAM”) #install.packages(“lme4”) #install.packages(“readr”) #install.packages(“optimx”) library(readr) library(tidyverse) library(lme4) library(TAM) library(optimx) library(knitr)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;#get the data read in. Have to be connected to internet. eirtdata &amp;lt;- read_csv(“&lt;a href=&#34;https://raw.githubusercontent.com/danielbkatz/EIRT/master/eirtdata.csv&#34; class=&#34;uri&#34;&gt;https://raw.githubusercontent.com/danielbkatz/EIRT/master/eirtdata.csv&lt;/a&gt;”)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;#get rid of the extra column eirtdata &amp;lt;- eirtdata[-1]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;#optional, if you want to save the data as a csv file on your computer. #Note, it adds a column. #write.csv(eirtdata, “eirtdata.csv”)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;#make sure these person level covariates are treated as factors eirtdata &amp;lt;- eirtdata %&amp;gt;% mutate(treat = ifelse(treat==1, “treat”, “not-treat”)) eirtdata&lt;span class=&#34;math inline&#34;&gt;\(treat &amp;lt;- as.factor(eirtdata\)&lt;/span&gt;treat) eirtdata&lt;span class=&#34;math inline&#34;&gt;\(proflevel &amp;lt;- as.factor(eirtdata\)&lt;/span&gt;proflevel) eirtdata&lt;span class=&#34;math inline&#34;&gt;\(abilcov &amp;lt;- as.factor(eirtdata\)&lt;/span&gt;abilcov) ``` #1. The Data Once the data is read in, let’s describe the data set. The data set comes from a general test given to a set of first year undergrads at UCSB. The test was administered to 1500 students in a large biology class. Approximately half the students are in a class that is run the standard way. The other class involves an all together different curriculum. Therefore, there’s a treatment and control group.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;#2. The variables: 1. &lt;code&gt;id&lt;/code&gt;: Random Student ID 2. &lt;code&gt;Math...&lt;/code&gt; Math Question from the test scored correct or incorrect (1 or 0) 3. &lt;code&gt;Science...&lt;/code&gt; Science type question scored correct or incorrect (1 or 0) 4. &lt;code&gt;ELA...&lt;/code&gt; Reading Comprehension type question, science related scored correct or incorrect (1 or 0) 5. &lt;code&gt;MathWordProb...&lt;/code&gt; Math Word Problem Type Question scored correct or incorrect (1 or 0) 6. &lt;code&gt;treat&lt;/code&gt;: 1 if student was assigned to treatment class, 0 if assigned to standard class 7. &lt;code&gt;proflevel&lt;/code&gt;: Categorical variable representing proficiency category on previous chemistry exam. 1 is the lowest, least proficient category. 4 is the most proficient. 8. &lt;code&gt;abilcov&lt;/code&gt;: Whether student is a chemistry(3), molecular biology(2), or other (1) major. Categorical.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;There are 40 items on the test in total.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;r #to get a sense of what&#39;s in the dataset. #names(tells us what the column names are) names(eirtdata)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;##  [1] &amp;quot;id&amp;quot;              &amp;quot;Math.1&amp;quot;          &amp;quot;Math.2&amp;quot; ##  [4] &amp;quot;Math.3&amp;quot;          &amp;quot;Math.4&amp;quot;          &amp;quot;Math.5&amp;quot; ##  [7] &amp;quot;Math.6&amp;quot;          &amp;quot;Math.7&amp;quot;          &amp;quot;Math.8&amp;quot; ## [10] &amp;quot;Math.9&amp;quot;          &amp;quot;Math.10&amp;quot;         &amp;quot;Science.1&amp;quot; ## [13] &amp;quot;Science.2&amp;quot;       &amp;quot;Science.3&amp;quot;       &amp;quot;Science.4&amp;quot; ## [16] &amp;quot;Science.5&amp;quot;       &amp;quot;Science.6&amp;quot;       &amp;quot;Science.7&amp;quot; ## [19] &amp;quot;Science.8&amp;quot;       &amp;quot;Science.9&amp;quot;       &amp;quot;Science.10&amp;quot; ## [22] &amp;quot;ELA.1&amp;quot;           &amp;quot;ELA.2&amp;quot;           &amp;quot;ELA.3&amp;quot; ## [25] &amp;quot;ELA.4&amp;quot;           &amp;quot;ELA.5&amp;quot;           &amp;quot;ELA.6&amp;quot; ## [28] &amp;quot;ELA.7&amp;quot;           &amp;quot;ELA.8&amp;quot;           &amp;quot;ELA.9&amp;quot; ## [31] &amp;quot;ELA.10&amp;quot;          &amp;quot;MathWordProb.1&amp;quot;  &amp;quot;MathWordProb.2&amp;quot; ## [34] &amp;quot;MathWordProb.3&amp;quot;  &amp;quot;MathWordProb.4&amp;quot;  &amp;quot;MathWordProb.5&amp;quot; ## [37] &amp;quot;MathWordProb.6&amp;quot;  &amp;quot;MathWordProb.7&amp;quot;  &amp;quot;MathWordProb.8&amp;quot; ## [40] &amp;quot;MathWordProb.9&amp;quot;  &amp;quot;MathWordProb.10&amp;quot; &amp;quot;treat&amp;quot; ## [43] &amp;quot;proflevel&amp;quot;       &amp;quot;abilcov&amp;quot;&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Normally, it would be wise to look at descriptives. We’ll skip that since the emphasis is on fitting the models in TAM.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;r #just to check out the data, are there #high performing students in both treatment groups? table(eirtdata$treat, eirtdata$proflevel)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;## ##               1   2   3   4 ##   not-treat 185 214 170 191 ##   treat     193 169 211 167&lt;/code&gt; # 3. Running the Rasch Model Let’s run some basic IRT using tam on this data. This should help us get an idea.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;```r #fit the first IRT model. Have to subset the data since it contains person covariates. mod1 &amp;lt;- tam.mml(eirtdata[2:40])&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;###4. view fit statistics. #It’s a lot easier to interpret these models if the data fit well. #The data fits really well. #If there are any outliers or anything like that, it would be revealed here.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;#get item fit mod1fit &amp;lt;- tam.fit(mod1) ```&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;r #item difficulties. Just show the first 10 items difficulties head(as.data.frame(mod1$xsi))&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;##               xsi     se.xsi ## Math.1 -1.1901775 0.06170396 ## Math.2 -0.5384382 0.05552351 ## Math.3  0.2070387 0.05424712 ## Math.4  0.7624491 0.05714235 ## Math.5  0.8450950 0.05786723 ## Math.6 -0.1907538 0.05419563&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;r #view the range of fit statistics, particularly infit range(mod1fit$itemfit$Infit)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;## [1] 0.9578577 1.0304389&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;r #Get the sample size adjusted acceptable item fit range: 2* (2/sqrt(1500))&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;## [1] 0.1032796&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;The smalles infit value is .96, the larges it 1.03. Therefore, items are fitting pretty well, though, a few wouldn’t meet the acceptable standard based on certain fit criteria.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;This is all to say, we’re good to start running our latent regressions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;#4. Latent Regression in Two Parts Example Q1. Is there a noticable difference in general ability (based on the test we’re analyzing) between groups who were in the treatment group (coded as 1) and those who were not (coded as 0)?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;One of the advantages of the latent regression approach is that it gets you item and student level information, potentially, and takes measurement error into account. If you were to simply regress test total score on the group identifier, you would have no measurement error. Plus, this regression approach wouldn’t really be a latent variable model. It takes the observed score and regresses it on the observed student classification.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;##Part I. Two Ways to Analyze Group Differences in TAM Treat the “treat” variable as placing students in groups, 1 and 0. We can do this two ways in TAM.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Formula for latent regression: &lt;span class=&#34;math inline&#34;&gt;\(\theta = \beta_1*X_1 + \epsilon\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the regression coefficient for 1. &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; takes on a value of 1 if the student is in the treatment group. Error is basically person specific (though, drawn from a normal distribution).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;With a dichotomous treatment variable, there are a few ways to do this in TAM. The first treats the data as if it comes from two “groups.” This method gets us group variances. So for instance, we can not only see if the two groups have major differeces via their theta estimates, we can see if their underlying distributions have different “shapes”&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;```r #take the treatment variable and make it its own R object treat &amp;lt;- eirtdata$treat&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;#add a simple TAM command latg &amp;lt;- tam.mml(eirtdata[2:40], group = treat)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;summary(latg) ```&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Under the section, “covariances, variances” we see that the two groups have pretty similar distributions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;```r #the next way, and I find this to be the most intuitive way, #but you don’t get group variances. #You have to specify a formula: formulay1 &amp;lt;- ~treat&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;#and then add dataY which can have many columns. lat1 &amp;lt;- tam.mml(eirtdata[2:40], dataY = eirtdata$treat, formulaY = formulay1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;#unfortunately, as far as I can tell, #this is the only way to get standard errors in TAM for your regression coefficients. se&amp;lt;- tam.se(lat1) summary(lat1) ```&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;r # get the unstandardized regression coefficient. #You can save these in an object if you like. #get standardized regression coefficients (using yx) kable(lat1$latreg_stand$beta_stand)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;parm dim est StdYX StdX StdY&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Intercept 1 0.0000000 NA NA NA Y1 1 0.6989754 0.547852 0.3495732 1.095436&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get R^2 estimate
lat1$latreg_stand$R2_theta&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3001418&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get standard error
se$beta&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    est.Dim1    se.Dim1
## 1 0.0000000 0.00000000
## 2 0.6989754 0.02448985&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that the latent regression explains about 30% of the variance in theta estimates (the rest going to person ability and error).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Let&amp;#39;s check standard errors of the regression estimates. 
se$beta&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    est.Dim1    se.Dim1
## 1 0.0000000 0.00000000
## 2 0.6989754 0.02448985&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#note, this also works below, but gets slightly different estimates 
#(a group mean is not held to zero)
#like &amp;lt;- IRT.likelihood(lat1)
#latregcom &amp;lt;- tam.latreg(like, dataY = eirtdata$treat, formulaY = formulay1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Let&amp;#39;s compare person ability parameters between the standard Rasch model and the latent regression model. 
head(mod1$person)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   pid case pweight score max         EAP    SD.EAP
## 1   1    1       1    23  39  0.05383554 0.3182850
## 2   2    2       1    26  39  0.39026644 0.3432272
## 3   3    3       1    16  39 -0.67112535 0.3122953
## 4   4    4       1    20  39 -0.25948566 0.3351358
## 5   5    5       1    19  39 -0.37144597 0.3318124
## 6   6    6       1    20  39 -0.25948566 0.3351358&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#theta estimates 
head(lat1$person)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   pid case pweight score max          EAP    SD.EAP
## 1   1    1       1    23  39  0.523588646 0.3041857
## 2   2    2       1    26  39  0.807582572 0.3265364
## 3   3    3       1    16  39 -0.388009891 0.3182653
## 4   4    4       1    20  39 -0.004515606 0.2869874
## 5   5    5       1    19  39  0.119659588 0.3024843
## 6   6    6       1    20  39 -0.004515606 0.2869874&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, the person parameters, the EAP estimates are quite different after “adjusting for” a student being in the treatment group or the non-treatment group. The formula now looks like:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Log[Pr(X=1|\theta_p, \delta_i)] = \beta_1*treat + \theta - \delta_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In this model, the variable, &lt;code&gt;treat&lt;/code&gt; is often called a “fixed effect.” TAM constrains the model so that the reference category fixed effect (no treatment) 0, has a value of zero. So, the model, for person 1, (who was in the treatment group) and item 1, looks like this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Fixed effect of &lt;code&gt;treat&lt;/code&gt; = .70 logits (rounded)&lt;/li&gt;
&lt;li&gt;Student was in the “treatment group” = 1&lt;/li&gt;
&lt;li&gt;.51 logits is the student’s ability after adjusting for the student being in the treatment group.&lt;/li&gt;
&lt;li&gt;Item difficulty for item 1 is -.85 logits.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Logit[Pr(X=1|\theta_1, \delta_1)] = .70*1+ .51 - (-.85)*1 + \epsilon\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We’ve decomposed the variance of theta.&lt;/p&gt;
&lt;div id=&#34;part-ii.adding-to-the-latent-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part II.Adding to the Latent Regression model&lt;/h2&gt;
&lt;p&gt;We can make the latent regression model more complicated by adding predictors beyond just treatment/not-treatment. 1. Create a matrix of covariates. 2. Create a latent regression formula object for formulaY1 3. Run the model.&lt;/p&gt;
&lt;p&gt;We’ll make the model more complicated by predicting theta with a latent regression controlling for proficiency level.&lt;/p&gt;
&lt;p&gt;So the model is now: &lt;span class=&#34;math inline&#34;&gt;\(\theta = \beta_1*treat + \beta_2*proflevel + \epsilon\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And the full model will now look something like: &lt;span class=&#34;math inline&#34;&gt;\(Log[Pr(X=1|\theta_p, \delta_i)] = \beta_1*treat + \beta_2*proflevel + \theta - \delta_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#this gets all the person level covariates into a single dataframe
daty &amp;lt;- eirtdata %&amp;gt;% select(treat, proflevel, abilcov)

#create the latent regression formula. Could also add an interaction
formulay2 &amp;lt;- ~ treat + proflevel

#now run the model
latreg2 &amp;lt;- tam.mml(eirtdata[2:40], dataY = daty, formulaY = formulay2)

#get standard errors
selatreg2 &amp;lt;- tam.se(latreg2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#view latent regression coefficients
kable(latreg2$latreg_stand$beta_stand)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parm&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;dim&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;est&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;StdYX&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;StdX&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;StdY&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Intercept&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;treattreat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5885051&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3000734&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.176722&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;proflevel2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5132791&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2617163&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.176722&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;proflevel3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5123953&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2612657&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.176722&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;proflevel4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0035342&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5116929&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.353445&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#view standard errors
kable(selatreg2$beta)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;est.Dim1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;se.Dim1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0011625&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0016158&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0016201&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0016713&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note all estiimates are statistically significant. The last step in this section is comparing overall model fit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;comparemod &amp;lt;- CDM::IRT.compareModels(mod1, lat1, latreg2)
kable(comparemod$IC)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;loglike&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Deviance&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Npars&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Nobs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AIC&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BIC&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AIC3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AICc&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;CAIC&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mod1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-31109.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62218.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62298.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62510.57&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62338.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62300.29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62550.57&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lat1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-30923.31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61846.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61928.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62146.47&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61969.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61930.99&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62187.47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;latreg2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-27663.39&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55326.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;44&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55414.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55648.55&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55458.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55417.49&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55692.55&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;the-item-side-the-linear-logistic-test-model-lltm&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;5. The Item Side: The Linear Logistic Test Model (LLTM)&lt;/h1&gt;
&lt;p&gt;The LLTM is simply a more parsimonious Rasch model. Instead of each individual item being estimated, estimated item difficulties are made just based on item indicators. For instance, the data we have has four item types. Each item type gets its own difficulty estimate. However, there are some complications here. There is an assumption that each item indicator is responsible for the item difficulty. This is not a safe assumption.&lt;/p&gt;
&lt;p&gt;The other unfortunate part about this is that the simplest way to go about fitting this model is by converting the data to “long” data. After that is done, we’ll create an indicator for each variable type (a categorical variable, denoting math, ela, science, or wordprob type item.&lt;/p&gt;
&lt;p&gt;To make the data long, we’ll use the “gather” function from tidyr in the tidyverse package. Then we’ll add an indicator based on if_else statements.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#change the name of the mathwordproblem items
names(eirtdata)[32:41] &amp;lt;- paste0(&amp;quot;WordProb.&amp;quot;, 1:10)

#note the nested ifelse statements. 
#Basically, if each var contains a certain value, such as &amp;quot;Math,&amp;quot; 
#it gets recoded into its own column using &amp;quot;Mutate&amp;quot; from dplyr. 

eirtlong &amp;lt;- gather(eirtdata, key = &amp;quot;item&amp;quot;, value = &amp;quot;response&amp;quot;, Math.1:WordProb.10) %&amp;gt;%
  mutate(ittype = if_else(grepl(pattern = &amp;quot;Math.&amp;quot;, x = item), 1,
         if_else(grepl(pattern = &amp;quot;Science.&amp;quot;, x = item), 2,
        if_else(grepl(pattern = &amp;quot;ELA.&amp;quot;, x = item), 3,4))))

head(eirtlong)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##      id treat     proflevel abilcov item   response ittype
##   &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     1 treat     4         1       Math.1        1      1
## 2     2 treat     3         2       Math.1        1      1
## 3     3 not-treat 1         2       Math.1        1      1
## 4     4 not-treat 2         1       Math.1        1      1
## 5     5 treat     1         2       Math.1        0      1
## 6     6 not-treat 2         1       Math.1        0      1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To set up the LLTM, we have to use TAM.mml.mfr using the facets formula. TAM will create so-called “pseudo facets” for parameters that don’t have estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;formulaa &amp;lt;- ~ittype
facets &amp;lt;- as.data.frame(eirtlong[c(5,7)])

#just to make it easier to call
names(facets) &amp;lt;- c(&amp;quot;item&amp;quot;, &amp;quot;ittype&amp;quot;)

#only want to use the response column. Have to add an id column
lltm &amp;lt;- tam.mml.mfr(eirtlong[6], facets = facets, 
                    formulaA = formulaa, pid = eirtlong$id)

control &amp;lt;- glmerControl(optimizer = &amp;quot;optimx&amp;quot;, 
                        calc.derivs = F, optCtrl = list(method=&amp;quot;nlminb&amp;quot;, starttests = F, kkt=F))


#same thing but in lme4
lltmme1 &amp;lt;- glmer(data=eirtlong, response~-1 + as.factor(ittype) + (1|id),
                 family = &amp;quot;binomial&amp;quot;, control = control)

#random item in lme4 (I don&amp;#39;t know how to do this in TAM)
lltmlmer &amp;lt;- glmer(data=eirtlong, response~-1 + as.factor(ittype) + (1|id) + (1|item), family = &amp;quot;binomial&amp;quot;, control = control)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so the LLTM model fit in TAM will only give you “difficulties” for the particular item properties. Now, instead of conceptualizing the Rasch model as ability - item difficulty, the model is “ability - item property difficulty.” There will only be as many item properties as you specify. There can be “crossloadings.”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get property difficulties
kable(lltm$xsi.facets)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;facet&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;xsi&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;se.xsi&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ittype1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ittype&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1092315&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0167853&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ittype2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ittype&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0063631&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0167639&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ittype3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ittype&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.2873576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0198834&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ittype4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ittype&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0249119&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0167649&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF101&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF102&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF103&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF104&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF105&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF106&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF107&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF108&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF109&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF110&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(lltmme1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## as.factor(ittype)1 as.factor(ittype)2 as.factor(ittype)3 
##        0.109420105       -0.006163771        1.287211963 
## as.factor(ittype)4 
##       -0.024710713&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, let’s compare the overall fit of the models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kable(CDM::IRT.compareModels(mod1, lat1, latreg2, lltm)$IC)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;loglike&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Deviance&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Npars&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Nobs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AIC&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BIC&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AIC3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AICc&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;CAIC&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mod1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-31109.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62218.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62298.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62510.57&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62338.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62300.29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62550.57&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lat1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-30923.31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61846.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61928.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62146.47&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61969.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61930.99&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62187.47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;latreg2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-27663.39&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55326.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;44&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55414.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55648.55&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55458.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55417.49&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55692.55&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lltm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-38564.85&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77129.71&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77139.71&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77166.27&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77144.71&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77139.75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77171.27&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It is perhaps of no surprise that the most complicated model has the best fit.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/tutorial/eirt2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/tutorial/eirt2/</guid>
      <description>


&lt;p&gt;+++ title = “Overview”&lt;/p&gt;
&lt;p&gt;date = 2018-09-09T00:00:00 # lastmod = 2018-09-09T00:00:00&lt;/p&gt;
&lt;p&gt;draft = false # Is this a draft? true/false toc = true # Show table of contents? true/false type = “docs” # Do not modify.&lt;/p&gt;
&lt;div id=&#34;add-menu-entry-to-sidebar.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Add menu entry to sidebar.&lt;/h1&gt;
&lt;p&gt;[menu.tutorial] name = “Explanatory IRT” weight = 1&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;featured-image.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Featured image.&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;uncomment-below-lines-to-use.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Uncomment below lines to use.&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;header&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;[header]&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;image-headersgetting-started.png&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;image = “headers/getting-started.png”&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;caption-image-credit-academic&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;caption = “Image credit: &lt;a href=&#34;https://github.com/gcushen/hugo-academic/&#34;&gt;&lt;strong&gt;Academic&lt;/strong&gt;&lt;/a&gt;”&lt;/h1&gt;
&lt;p&gt;+++&lt;/p&gt;
&lt;div id=&#34;get-the-data-read-in&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get the Data Read in&lt;/h2&gt;
&lt;p&gt;First, I want to make sure everybody gets the data read into R in the exact same way.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install packages to get data
#install.packages(&amp;quot;tidyverse&amp;quot;)
#install.packages(&amp;quot;TAM&amp;quot;)
#install.packages(&amp;quot;lme4&amp;quot;)
#install.packages(&amp;quot;readr&amp;quot;)
#install.packages(&amp;quot;optimx&amp;quot;)
library(readr)
library(tidyverse)
library(lme4)
library(TAM)
library(optimx)
library(knitr)

#get the data read in. Have to be connected to internet. 
eirtdata &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/danielbkatz/EIRT/master/eirtdata.csv&amp;quot;)

#get rid of the extra column
eirtdata &amp;lt;- eirtdata[-1]

#optional, if you want to save the data as a csv file on your computer. 
#Note, it adds a column.
#write.csv(eirtdata, &amp;quot;eirtdata.csv&amp;quot;)

#make sure these person level covariates are treated as factors
eirtdata &amp;lt;- eirtdata %&amp;gt;% mutate(treat = ifelse(treat==1, &amp;quot;treat&amp;quot;, &amp;quot;not-treat&amp;quot;))
eirtdata$treat &amp;lt;- as.factor(eirtdata$treat)
eirtdata$proflevel &amp;lt;- as.factor(eirtdata$proflevel)
eirtdata$abilcov &amp;lt;- as.factor(eirtdata$abilcov)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;1. The Data&lt;/h1&gt;
&lt;p&gt;Once the data is read in, let’s describe the data set.&lt;br /&gt;
The data set comes from a general test given to a set of first year undergrads at UCSB. The test was administered to 1500 students in a large biology class. Approximately half the students are in a class that is run the standard way. The other class involves an all together different curriculum. Therefore, there’s a treatment and control group.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-variables&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;2. The variables:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;id&lt;/code&gt;: Random Student ID&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Math...&lt;/code&gt; Math Question from the test scored correct or incorrect (1 or 0)&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Science...&lt;/code&gt; Science type question scored correct or incorrect (1 or 0)&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ELA...&lt;/code&gt; Reading Comprehension type question, science related scored correct or incorrect (1 or 0)&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MathWordProb...&lt;/code&gt; Math Word Problem Type Question scored correct or incorrect (1 or 0)&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;treat&lt;/code&gt;: 1 if student was assigned to treatment class, 0 if assigned to standard class&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;proflevel&lt;/code&gt;: Categorical variable representing proficiency category on previous chemistry exam. 1 is the lowest, least proficient category. 4 is the most proficient.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;abilcov&lt;/code&gt;: Whether student is a chemistry(3), molecular biology(2), or other (1) major. Categorical.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are 40 items on the test in total.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#to get a sense of what&amp;#39;s in the dataset. 
#names(tells us what the column names are)
names(eirtdata)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;id&amp;quot;              &amp;quot;Math.1&amp;quot;          &amp;quot;Math.2&amp;quot;         
##  [4] &amp;quot;Math.3&amp;quot;          &amp;quot;Math.4&amp;quot;          &amp;quot;Math.5&amp;quot;         
##  [7] &amp;quot;Math.6&amp;quot;          &amp;quot;Math.7&amp;quot;          &amp;quot;Math.8&amp;quot;         
## [10] &amp;quot;Math.9&amp;quot;          &amp;quot;Math.10&amp;quot;         &amp;quot;Science.1&amp;quot;      
## [13] &amp;quot;Science.2&amp;quot;       &amp;quot;Science.3&amp;quot;       &amp;quot;Science.4&amp;quot;      
## [16] &amp;quot;Science.5&amp;quot;       &amp;quot;Science.6&amp;quot;       &amp;quot;Science.7&amp;quot;      
## [19] &amp;quot;Science.8&amp;quot;       &amp;quot;Science.9&amp;quot;       &amp;quot;Science.10&amp;quot;     
## [22] &amp;quot;ELA.1&amp;quot;           &amp;quot;ELA.2&amp;quot;           &amp;quot;ELA.3&amp;quot;          
## [25] &amp;quot;ELA.4&amp;quot;           &amp;quot;ELA.5&amp;quot;           &amp;quot;ELA.6&amp;quot;          
## [28] &amp;quot;ELA.7&amp;quot;           &amp;quot;ELA.8&amp;quot;           &amp;quot;ELA.9&amp;quot;          
## [31] &amp;quot;ELA.10&amp;quot;          &amp;quot;MathWordProb.1&amp;quot;  &amp;quot;MathWordProb.2&amp;quot; 
## [34] &amp;quot;MathWordProb.3&amp;quot;  &amp;quot;MathWordProb.4&amp;quot;  &amp;quot;MathWordProb.5&amp;quot; 
## [37] &amp;quot;MathWordProb.6&amp;quot;  &amp;quot;MathWordProb.7&amp;quot;  &amp;quot;MathWordProb.8&amp;quot; 
## [40] &amp;quot;MathWordProb.9&amp;quot;  &amp;quot;MathWordProb.10&amp;quot; &amp;quot;treat&amp;quot;          
## [43] &amp;quot;proflevel&amp;quot;       &amp;quot;abilcov&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Normally, it would be wise to look at descriptives. We’ll skip that since the emphasis is on fitting the models in TAM.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#just to check out the data, are there 
#high performing students in both treatment groups? 
table(eirtdata$treat, eirtdata$proflevel)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            
##               1   2   3   4
##   not-treat 185 214 170 191
##   treat     193 169 211 167&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;running-the-rasch-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3. Running the Rasch Model&lt;/h1&gt;
&lt;p&gt;Let’s run some basic IRT using tam on this data. This should help us get an idea.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#fit the first IRT model. Have to subset the data since it contains person covariates.
mod1 &amp;lt;- tam.mml(eirtdata[2:40])

###4. view fit statistics.
#It&amp;#39;s a lot easier to interpret these models if the data fit well. 
#The data fits really well. 
#If there are any outliers or anything like that, it would be revealed here. 

#get item fit
mod1fit &amp;lt;- tam.fit(mod1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#item difficulties. Just show the first 10 items difficulties
head(as.data.frame(mod1$xsi))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               xsi     se.xsi
## Math.1 -1.1901775 0.06170396
## Math.2 -0.5384382 0.05552351
## Math.3  0.2070387 0.05424712
## Math.4  0.7624491 0.05714235
## Math.5  0.8450950 0.05786723
## Math.6 -0.1907538 0.05419563&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#view the range of fit statistics, particularly infit
range(mod1fit$itemfit$Infit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9606576 1.0290259&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Get the sample size adjusted acceptable item fit range:
2* (2/sqrt(1500))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1032796&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The smalles infit value is .96, the larges it 1.03. Therefore, items are fitting pretty well, though, a few wouldn’t meet the acceptable standard based on certain fit criteria.&lt;/p&gt;
&lt;p&gt;This is all to say, we’re good to start running our latent regressions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;latent-regression-in-two-parts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;4. Latent Regression in Two Parts&lt;/h1&gt;
&lt;p&gt;Example Q1. Is there a noticable difference in general ability (based on the test we’re analyzing) between groups who were in the treatment group (coded as 1) and those who were not (coded as 0)?&lt;/p&gt;
&lt;p&gt;One of the advantages of the latent regression approach is that it gets you item and student level information, potentially, and takes measurement error into account. If you were to simply regress test total score on the group identifier, you would have no measurement error. Plus, this regression approach wouldn’t really be a latent variable model. It takes the observed score and regresses it on the observed student classification.&lt;/p&gt;
&lt;div id=&#34;part-i.-two-ways-to-analyze-group-differences-in-tam&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part I. Two Ways to Analyze Group Differences in TAM&lt;/h2&gt;
&lt;p&gt;Treat the “treat” variable as placing students in groups, 1 and 0. We can do this two ways in TAM.&lt;/p&gt;
&lt;p&gt;Formula for latent regression: &lt;span class=&#34;math inline&#34;&gt;\(\theta = \beta_1*X_1 + \epsilon\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the regression coefficient for 1. &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; takes on a value of 1 if the student is in the treatment group. Error is basically person specific (though, drawn from a normal distribution).&lt;/p&gt;
&lt;p&gt;With a dichotomous treatment variable, there are a few ways to do this in TAM. The first treats the data as if it comes from two “groups.” This method gets us group variances. So for instance, we can not only see if the two groups have major differeces via their theta estimates, we can see if their underlying distributions have different “shapes”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#take the treatment variable and make it its own R object
treat &amp;lt;- eirtdata$treat

#add a simple TAM command
latg &amp;lt;- tam.mml(eirtdata[2:40], group = treat)

summary(latg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Under the section, “covariances, variances” we see that the two groups have pretty similar distributions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#the next way, and I find this to be the most intuitive way, 
#but you don&amp;#39;t get group variances. 
#You have to specify a formula:
formulay1 &amp;lt;- ~treat

#and then add dataY which can have many columns.
lat1 &amp;lt;- tam.mml(eirtdata[2:40], dataY = eirtdata$treat, formulaY = formulay1)

#unfortunately, as far as I can tell, 
#this is the only way to get standard errors in TAM for your regression coefficients. 
se&amp;lt;- tam.se(lat1)
summary(lat1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the unstandardized regression coefficient. 
#You can save these in an object if you like.
#get standardized regression coefficients (using yx)
kable(lat1$latreg_stand$beta_stand)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parm&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;dim&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;est&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;StdYX&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;StdX&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;StdY&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Intercept&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Y1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6989754&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.547852&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3495732&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.095436&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get R^2 estimate
lat1$latreg_stand$R2_theta&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3001418&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get standard error
se$beta&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    est.Dim1    se.Dim1
## 1 0.0000000 0.00000000
## 2 0.6989754 0.02448985&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that the latent regression explains about 30% of the variance in theta estimates (the rest going to person ability and error).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Let&amp;#39;s check standard errors of the regression estimates. 
se$beta&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    est.Dim1    se.Dim1
## 1 0.0000000 0.00000000
## 2 0.6989754 0.02448985&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#note, this also works below, but gets slightly different estimates 
#(a group mean is not held to zero)
#like &amp;lt;- IRT.likelihood(lat1)
#latregcom &amp;lt;- tam.latreg(like, dataY = eirtdata$treat, formulaY = formulay1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Let&amp;#39;s compare person ability parameters between the standard Rasch model and the latent regression model. 
head(mod1$person)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   pid case pweight score max         EAP    SD.EAP
## 1   1    1       1    23  39  0.05383554 0.3182850
## 2   2    2       1    26  39  0.39026644 0.3432272
## 3   3    3       1    16  39 -0.67112535 0.3122953
## 4   4    4       1    20  39 -0.25948566 0.3351358
## 5   5    5       1    19  39 -0.37144597 0.3318124
## 6   6    6       1    20  39 -0.25948566 0.3351358&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#theta estimates 
head(lat1$person)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   pid case pweight score max          EAP    SD.EAP
## 1   1    1       1    23  39  0.523588646 0.3041857
## 2   2    2       1    26  39  0.807582572 0.3265364
## 3   3    3       1    16  39 -0.388009891 0.3182653
## 4   4    4       1    20  39 -0.004515606 0.2869874
## 5   5    5       1    19  39  0.119659588 0.3024843
## 6   6    6       1    20  39 -0.004515606 0.2869874&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, the person parameters, the EAP estimates are quite different after “adjusting for” a student being in the treatment group or the non-treatment group. The formula now looks like:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Log[Pr(X=1|\theta_p, \delta_i)] = \beta_1*treat + \theta - \delta_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In this model, the variable, &lt;code&gt;treat&lt;/code&gt; is often called a “fixed effect.” TAM constrains the model so that the reference category fixed effect (no treatment) 0, has a value of zero. So, the model, for person 1, (who was in the treatment group) and item 1, looks like this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Fixed effect of &lt;code&gt;treat&lt;/code&gt; = .70 logits (rounded)&lt;/li&gt;
&lt;li&gt;Student was in the “treatment group” = 1&lt;/li&gt;
&lt;li&gt;.51 logits is the student’s ability after adjusting for the student being in the treatment group.&lt;/li&gt;
&lt;li&gt;Item difficulty for item 1 is -.85 logits.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Logit[Pr(X=1|\theta_1, \delta_1)] = .70*1+ .51 - (-.85)*1 + \epsilon\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We’ve decomposed the variance of theta.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-ii.adding-to-the-latent-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part II.Adding to the Latent Regression model&lt;/h2&gt;
&lt;p&gt;We can make the latent regression model more complicated by adding predictors beyond just treatment/not-treatment. 1. Create a matrix of covariates. 2. Create a latent regression formula object for formulaY1 3. Run the model.&lt;/p&gt;
&lt;p&gt;We’ll make the model more complicated by predicting theta with a latent regression controlling for proficiency level.&lt;/p&gt;
&lt;p&gt;So the model is now: &lt;span class=&#34;math inline&#34;&gt;\(\theta = \beta_1*treat + \beta_2*proflevel + \epsilon\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And the full model will now look something like: &lt;span class=&#34;math inline&#34;&gt;\(Log[Pr(X=1|\theta_p, \delta_i)] = \beta_1*treat + \beta_2*proflevel + \theta - \delta_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#this gets all the person level covariates into a single dataframe
daty &amp;lt;- eirtdata %&amp;gt;% select(treat, proflevel, abilcov)

#create the latent regression formula. Could also add an interaction
formulay2 &amp;lt;- ~ treat + proflevel

#now run the model
latreg2 &amp;lt;- tam.mml(eirtdata[2:40], dataY = daty, formulaY = formulay2)

#get standard errors
selatreg2 &amp;lt;- tam.se(latreg2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#view latent regression coefficients
kable(latreg2$latreg_stand$beta_stand)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parm&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;dim&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;est&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;StdYX&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;StdX&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;StdY&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Intercept&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;treattreat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5885051&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3000734&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.176722&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;proflevel2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5132791&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2617163&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.176722&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;proflevel3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5123953&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2612657&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.176722&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;proflevel4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0035342&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5116929&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.353445&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#view standard errors
kable(selatreg2$beta)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;est.Dim1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;se.Dim1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0011625&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0016158&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0016201&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0016713&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note all estiimates are statistically significant. The last step in this section is comparing overall model fit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;comparemod &amp;lt;- CDM::IRT.compareModels(mod1, lat1, latreg2)
kable(comparemod$IC)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;loglike&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Deviance&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Npars&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Nobs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AIC&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BIC&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AIC3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AICc&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;CAIC&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mod1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-31109.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62218.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62298.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62510.57&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62338.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62300.29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62550.57&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lat1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-30923.31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61846.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61928.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62146.47&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61969.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61930.99&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62187.47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;latreg2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-27663.39&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55326.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;44&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55414.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55648.55&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55458.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55417.49&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55692.55&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-item-side-the-linear-logistic-test-model-lltm&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;5. The Item Side: The Linear Logistic Test Model (LLTM)&lt;/h1&gt;
&lt;p&gt;The LLTM is simply a more parsimonious Rasch model. Instead of each individual item being estimated, estimated item difficulties are made just based on item indicators. For instance, the data we have has four item types. Each item type gets its own difficulty estimate. However, there are some complications here. There is an assumption that each item indicator is responsible for the item difficulty. This is not a safe assumption.&lt;/p&gt;
&lt;p&gt;The other unfortunate part about this is that the simplest way to go about fitting this model is by converting the data to “long” data. After that is done, we’ll create an indicator for each variable type (a categorical variable, denoting math, ela, science, or wordprob type item.&lt;/p&gt;
&lt;p&gt;To make the data long, we’ll use the “gather” function from tidyr in the tidyverse package. Then we’ll add an indicator based on if_else statements.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#change the name of the mathwordproblem items
names(eirtdata)[32:41] &amp;lt;- paste0(&amp;quot;WordProb.&amp;quot;, 1:10)

#note the nested ifelse statements. 
#Basically, if each var contains a certain value, such as &amp;quot;Math,&amp;quot; 
#it gets recoded into its own column using &amp;quot;Mutate&amp;quot; from dplyr. 

eirtlong &amp;lt;- gather(eirtdata, key = &amp;quot;item&amp;quot;, value = &amp;quot;response&amp;quot;, Math.1:WordProb.10) %&amp;gt;%
  mutate(ittype = if_else(grepl(pattern = &amp;quot;Math.&amp;quot;, x = item), 1,
         if_else(grepl(pattern = &amp;quot;Science.&amp;quot;, x = item), 2,
        if_else(grepl(pattern = &amp;quot;ELA.&amp;quot;, x = item), 3,4))))

head(eirtlong)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##      id treat     proflevel abilcov item   response ittype
##   &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     1 treat     4         1       Math.1        1      1
## 2     2 treat     3         2       Math.1        1      1
## 3     3 not-treat 1         2       Math.1        1      1
## 4     4 not-treat 2         1       Math.1        1      1
## 5     5 treat     1         2       Math.1        0      1
## 6     6 not-treat 2         1       Math.1        0      1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To set up the LLTM, we have to use TAM.mml.mfr using the facets formula. TAM will create so-called “pseudo facets” for parameters that don’t have estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;formulaa &amp;lt;- ~ittype
facets &amp;lt;- as.data.frame(eirtlong[c(5,7)])

#just to make it easier to call
names(facets) &amp;lt;- c(&amp;quot;item&amp;quot;, &amp;quot;ittype&amp;quot;)

#only want to use the response column. Have to add an id column
lltm &amp;lt;- tam.mml.mfr(eirtlong[6], facets = facets, 
                    formulaA = formulaa, pid = eirtlong$id)

control &amp;lt;- glmerControl(optimizer = &amp;quot;optimx&amp;quot;, 
                        calc.derivs = F, optCtrl = list(method=&amp;quot;nlminb&amp;quot;, starttests = F, kkt=F))


#same thing but in lme4
lltmme1 &amp;lt;- glmer(data=eirtlong, response~-1 + as.factor(ittype) + (1|id),
                 family = &amp;quot;binomial&amp;quot;, control = control)

#random item in lme4 (I don&amp;#39;t know how to do this in TAM)
lltmlmer &amp;lt;- glmer(data=eirtlong, response~-1 + as.factor(ittype) + (1|id) + (1|item), family = &amp;quot;binomial&amp;quot;, control = control)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so the LLTM model fit in TAM will only give you “difficulties” for the particular item properties. Now, instead of conceptualizing the Rasch model as ability - item difficulty, the model is “ability - item property difficulty.” There will only be as many item properties as you specify. There can be “crossloadings.”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get property difficulties
kable(lltm$xsi.facets)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;facet&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;xsi&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;se.xsi&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ittype1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ittype&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1092315&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0167853&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ittype2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ittype&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0063631&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0167639&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ittype3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ittype&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.2873576&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0198834&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ittype4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ittype&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0249119&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0167649&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF101&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF102&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF103&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF104&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF105&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF106&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF107&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF108&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF109&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;psfPF110&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(lltmme1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## as.factor(ittype)1 as.factor(ittype)2 as.factor(ittype)3 
##        0.109420105       -0.006163771        1.287211963 
## as.factor(ittype)4 
##       -0.024710713&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, let’s compare the overall fit of the models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kable(CDM::IRT.compareModels(mod1, lat1, latreg2, lltm)$IC)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;loglike&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Deviance&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Npars&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Nobs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AIC&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BIC&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AIC3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AICc&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;CAIC&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mod1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-31109.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62218.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62298.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62510.57&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62338.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62300.29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62550.57&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lat1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-30923.31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61846.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61928.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62146.47&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61969.63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61930.99&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62187.47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;latreg2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-27663.39&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55326.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;44&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55414.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55648.55&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55458.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55417.49&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55692.55&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lltm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-38564.85&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77129.71&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77139.71&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77166.27&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77144.71&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77139.75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77171.27&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It is perhaps of no surprise that the most complicated model has the best fit.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
