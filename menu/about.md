---
layout: page
title: About
permalink: /about/
---

<div style='float: right; padding-left: 10px' >
  <img src='../assets/img/headshot.jpg' width="200" height="300" />
</div>

I'm currently an ontology engineer at NWEA where I work on projects related to educational measurement, curriculum development, and instructional recommendation systems. My background in academia was a mix of statistics and sub-fields of philosophy - philosophy of measurement & philosophy of language. This drew me to ontology in a philosophical sense and projects trying to bring these frameworks to measurement in the human sciences. 

Overall, I like to ask: what is *it* that we measure when we talk about assessment in education, psychology, or similar? 


## What might an ontology engineer do?
Good question - here is a rough and broad example:
1. Work with subject matter experts like learning scientists in developing conceptual clarity around the things relevant to an organization (or scientific field) and how these things  (e.g. educational standards, articulated student abilities, assessment items) relate to each other.
2. Work with consumers of the ontology (e.g. machine learning engineers, data scientists, data engineers, subject matter experts on other teams) to consider how the ontology should be structured
3. Move these semantics into a machine readable language (such as the Web Ontology Language). 
4. Aligning data to this ontology, linking data across fields, ideally reducing ambiguity around internal vocabularies or what an organization's data refer to.
5. Developing design patterns, data models, and querying methods enabling machine learning engineers, data scientists, 

## How did I get here?
I did my PhD at UCSB in the Education Department under Andy Maul in educational measurement. Early in grad school, I devoted time to studying statistics as applied to educational research, causal inference, and psychometrics. I also dove into exciting-to-me debates about test validity theory where I was introduced to philosophy of science. As I joined more projects as the consulting methodologist, it often seemed like conceptual issues were masquerading as statistical issues. I had a creeping feeling that I could contribute more to these projects by helping establish conceptual clarity around defining the things we intended to measure and identifying when researchers (including me) were being [bewitched by our words.](https://philosophynow.org/issues/59/Bewitched)
<br>
At the same time, there was burgeoning work comparing and contrasting traditions of measurement in the [human sciences and the field of metrology (measurement sciences outside of the social sciences)](https://link.springer.com/book/10.1007/978-3-031-22448-5) that captured my interest - particularly taking advantage of concepts already developed in metrology like the concept of a measurand. 
<br>
These interests turned into a job at NWEA where I worked on an R&D team in ontology and measurement developing very specific cognitive models in service of classroom-based assessments: focusing on defining the things we intended to measure and turning cognitive models into ontologies and then psychometric models. After NWEA was purchased by HMH, my work became more technical - working as an ontology engineer, deploying enterprise level ontologies and serving machine learning systems.


## What other interests do I have?
I continue to chip away at projects related to academic interests from my PhD studies. Substantively, I maintain an interest in literacy and reading research as well as concepts of fairness in educational testing and psychometrics. On the statistical front, I’m interested in item response theory (particularly Rasch modelling), and general causal modelling, especially in service of program evaluation. How we use statistics to know what’s true, make decisions, and update beliefs is a topic that blends nicely with some of the program evaluation work I've consulted on.