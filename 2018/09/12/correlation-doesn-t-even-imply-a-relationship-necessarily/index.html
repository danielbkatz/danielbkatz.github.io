<!DOCTYPE html>
<html lang="en-us"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Correlation Doesn&#39;t Even Imply ... Correlation, Necessarily - Daniel Katz</title>
    <base href="https://danielbkatz.github.io/">
    
    
    
    
    <link rel="stylesheet" href="https://danielbkatz.github.io/css/main.min.d1a35de747f32f38def9b85df0ddc1ae0d95ca476bb14c10d484610ddcc1acda.css">
</head>
<body><header>
    <nav class="breadcrumb">
        
        <a href="https://danielbkatz.github.io/post/">/Posts</a>
        
        <a href="https://danielbkatz.github.io/about/">/About</a>
        
        <a href="https://danielbkatz.github.io/contact/">/Contact</a>
        
        <a href="https://danielbkatz.github.io/cv/">/C.V.</a>
        
        <a href="https://danielbkatz.github.io/presentations/">/Presentations</a>
        
    </nav>
</header>
<div class="container">
<main id="single">
    <h1>Correlation Doesn&#39;t Even Imply ... Correlation, Necessarily</h1>
    <div class="post-date">
<time datetime="2018-09-12T00:00:00&#43;0000">12 Sep 2018, 00:00</time>
</div>
    <section class="post-content">
        


<p>There’s a problem with the various versions of the oft-heard-in-intro-stats-courses phrase “correlation does not imply causation.” It gives early statistics students the wrong impressions.</p>
<p>The idea seems simple: Just because there’s statistical correlation in the present does not mean that that there is a real world causal relationship (a complicated term, it turns out) between x and y. For instance, x could have a high correlation with y but actually, w is simply a mutual cause of x and y. Or something like that.</p>
<p>The phrase is problematic because it’s actually not accurate.</p>
<p>1.) The first problem is that the only thing that may indicate a causal relationship statistically is correlation. The more accurate phrase might be something like, “correlation does not <strong><em>necessarily</em></strong> imply causation”</p>
<p>2.) The next problem is that, paradoxically, the phrase does not go far enough. Correlation present in data does not even indicate a real world relationship, let alone a causal one!</p>
<p>Point 2 can be demonstrated. We’ll generate completely random distributions and then correlate them. Then we’ll do this over and over and look at how the correlations values vary.</p>
<div id="correlating-the-uncorrelated" class="section level3">
<h3>Correlating the Uncorrelated</h3>
<p>Let’s start by generating two random normal distributions of size 20, <span class="math inline">\(\mu\)</span> is 0, <span class="math inline">\(\sigma\)</span> is 1.</p>
<pre class="r"><code>set.seed(123)
dist1 &lt;- rnorm(20)
dist2 &lt;- rnorm(20)</code></pre>
<p>These two distributions, aside from being generated on my computer, have nothing to do with each other and represent nothing in the real world. If you have no interest in the R code, that’s fine, just pay attention to the fact that we’re working with random distributions that have no real world relationship.</p>
<p>We can correlate them.</p>
<pre class="r"><code>cor(dist1, dist2)</code></pre>
<pre><code>## [1] -0.09172278</code></pre>
<p>The Correlation is -.09, not very large.</p>
<p>Let’s do this again.</p>
<pre class="r"><code>set.seed(9201989)
dista &lt;- rnorm(20)

distb &lt;- rnorm(20)

cor(dista, distb)</code></pre>
<pre><code>## [1] -0.3213314</code></pre>
<p>Hm, -.32, we’re starting to get somewhere. But they’re random numbers. Let’s say we do this over and over again and graph the correlation coefficients. I created a function to do this as an exhibit.</p>
<p>It takes as input, the number of times to replicate creating the distribrutions of size <em>samples</em> and a particular correlation value, or <em>cor.cutoff</em>. The function returns the number of times a correlation value above this cutoff (cor.cutoff) is returned.</p>
<p>The code is below. It returns a list. Element 1 is the number of times a correlation value at least as large as cor.cutoff is returned. Element 2 is a line plot of correlation coefficients. Each replication returns one correlation coefficient. And the third element in the returned list is a dataframe containing each correlation coefficient for each replication.</p>
<pre class="r"><code>library(ggplot2)

totfunc &lt;- function(reps, samples, cor.cutoff){
random &lt;- function(samples){
  dist1 &lt;- rnorm(samples, 0, 1)
  dist2 &lt;- rnorm(samples, 0, 1)
distab &lt;- as.data.frame(cbind(dist1, dist2))
x1 &lt;- cor(dist1, dist2)}


test1 &lt;-replicate(reps, random(samples))

test2 &lt;- as.data.frame(cbind(test1, c(1:reps)))

corpl &lt;- ggplot(data = test2, aes(x=V2, y = test1)) + geom_line() + xlab(&quot;Replication Number&quot;) + ylab(&quot;Pearson&#39;s Correlation Coeffient Value&quot;)
x2 &lt;- sum(test2$test1 &gt;= cor.cutoff)

corpl
plotsr &lt;- list(x2, corpl, test2)
return(plotsr)
} </code></pre>
<p>Let’s see how this works. We’ll start with distributions of size 20 and correlate them. We’ll repeat this process 1000 times. we want to know how many correlation coefficients above the absolute value of .6 exist.</p>
<pre class="r"><code>set.seed(23)
testtot &lt;- totfunc(1000, 20, abs(.6))</code></pre>
<p>To see the plot of correlation coefficients:</p>
<pre class="r"><code>testtot[[2]]</code></pre>
<p><img src="https://danielbkatz.github.io/post/2018-09-12-correlation-doesn-t-even-imply-a-relationship-necessarily_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Not the pretties, but you get the idea. Correlation values are all over the place. How many times does the correlation value exceed the absolute value of .6?</p>
<pre class="r"><code>testtot[[1]]</code></pre>
<pre><code>## [1] 5</code></pre>
<p>Yep, 5 times. That’s fairly impressive. We were able to generate two random distributions, and depending on the sample, got correlation values that exceeded .6.</p>
<p>If you want to understand why a correlation coefficient doesn’t necessarily describe a real world relationship, this is why!</p>
<p>And if you want to play with some other numbers, say, with random distributions of size 1000 and do it a thousand times, we can.</p>
<pre class="r"><code>test2 &lt;- totfunc(1000, 1000, abs(.6))

test2[[1]]</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>test2[[2]]</code></pre>
<p><img src="https://danielbkatz.github.io/post/2018-09-12-correlation-doesn-t-even-imply-a-relationship-necessarily_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>

    </section>
</main>

        </div><footer>
    <ul class="lang-selector">
    
</ul>

    <span class="footer-text">Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a></span>
</footer>

<script src="https://danielbkatz.github.io/js/highlight.pack.13389e4e093fc0b3466287ead64c1f9fc3007d7703813a413de3f046ea09a346.js" integrity="sha256-EzieTgk/wLNGYofq1kwfn8MAfXcDgTpBPePwRuoJo0Y="></script>
<script>hljs.initHighlightingOnLoad();</script>
</body>
</html>
