---
layout: post
title: "Explanatory IRT tutorial with the TAM package in R"
author: Daniel Katz
date: '2019-03-15'
 
categories: R
tags: [IRT, Rasch, TAM, DIF]
status: publish
published: true
TOC: true
 
---
In this post, we'll go through the basics of running latent regression models in TAM. In essence, these are IRT models with covariates. These are especially useful for expanding on inferences or measurement claims made with the Rasch model. While not particularly conceptually difficult, there are a number of moving parts that I hope this will help clarify.
 
* TOC
{:toc}
### Get the Data Read in
First, I want to make sure everybody gets the data read into R in the exact same way. 
 

{% highlight r %}
#install packages to get data
#install.packages("tidyverse")
#install.packages("TAM")
#install.packages("lme4")
#install.packages("readr")
#install.packages("optimx")
library(readr)
library(tidyverse)
library(lme4)
library(TAM)
library(optimx)
library(knitr)
 
#get the data read in. Have to be connected to internet. 
eirtdata <- read_csv("https://raw.githubusercontent.com/danielbkatz/EIRT/master/eirtdata.csv")
 
#get rid of the extra column
eirtdata <- eirtdata[-1]
 
#optional, if you want to save the data as a csv file on your computer. 
#Note, it adds a column.
#write.csv(eirtdata, "eirtdata.csv")
 
#make sure these person level covariates are treated as factors
eirtdata <- eirtdata %>% mutate(treat = ifelse(treat==1, "treat", "not-treat"))
eirtdata$treat <- as.factor(eirtdata$treat)
eirtdata$proflevel <- as.factor(eirtdata$proflevel)
eirtdata$abilcov <- as.factor(eirtdata$abilcov)
{% endhighlight %}
### 1. The Data
Once the data is read in, let's describe the data set.  
The data set comes from a general test given to a set of first year undergrads at UCSB. The test was administered to 1500 students in a large biology class. Approximately half the students are in a class that is run the standard way. The other class involves an all together different curriculum. Therefore, there's a treatment and control group. 
 
### 2. The variables:  
1. `id`: Random Student ID  
2. `Math...` Math Question from the test scored correct or incorrect (1 or 0)  
3. `Science...` Science type question scored correct or incorrect (1 or 0)  
4. `ELA...` Reading Comprehension type question, science related scored correct or incorrect (1 or 0)  
5. `MathWordProb...` Math Word Problem Type Question scored correct or incorrect (1 or 0)  
6. `treat`: 1 if student was assigned to treatment class, 0 if assigned to standard class  
7. `proflevel`: Categorical variable representing proficiency category on previous chemistry exam. 1 is the lowest, least proficient category. 4 is the most proficient.   
8. `abilcov`: Whether student is a chemistry(3), molecular biology(2), or other (1) major. Categorical.  
  
There are 40 items on the test in total.
 
 

{% highlight r %}
#to get a sense of what's in the dataset. 
#names(tells us what the column names are)
names(eirtdata)
{% endhighlight %}



{% highlight text %}
##  [1] "id"              "Math.1"          "Math.2"          "Math.3"         
##  [5] "Math.4"          "Math.5"          "Math.6"          "Math.7"         
##  [9] "Math.8"          "Math.9"          "Math.10"         "Science.1"      
## [13] "Science.2"       "Science.3"       "Science.4"       "Science.5"      
## [17] "Science.6"       "Science.7"       "Science.8"       "Science.9"      
## [21] "Science.10"      "ELA.1"           "ELA.2"           "ELA.3"          
## [25] "ELA.4"           "ELA.5"           "ELA.6"           "ELA.7"          
## [29] "ELA.8"           "ELA.9"           "ELA.10"          "MathWordProb.1" 
## [33] "MathWordProb.2"  "MathWordProb.3"  "MathWordProb.4"  "MathWordProb.5" 
## [37] "MathWordProb.6"  "MathWordProb.7"  "MathWordProb.8"  "MathWordProb.9" 
## [41] "MathWordProb.10" "treat"           "proflevel"       "abilcov"
{% endhighlight %}
 
Normally, it would be wise to look at descriptives. We'll skip that since the emphasis is on fitting the models in TAM.
 

{% highlight r %}
#just to check out the data, are there 
#high performing students in both treatment groups? 
table(eirtdata$treat, eirtdata$proflevel)
{% endhighlight %}



{% highlight text %}
##            
##               1   2   3   4
##   not-treat 185 214 170 191
##   treat     193 169 211 167
{% endhighlight %}
### 3. Running the Rasch Model
Let's run some basic IRT using tam on this data. This should help us get an idea. 

{% highlight r %}
#fit the first IRT model. Have to subset the data since it contains person covariates.
mod1 <- tam.mml(eirtdata[2:40])
 
###4. view fit statistics.
#It's a lot easier to interpret these models if the data fit well. 
#The data fits really well. 
#If there are any outliers or anything like that, it would be revealed here. 
 
#get item fit
mod1fit <- tam.fit(mod1)
{% endhighlight %}

{% highlight r %}
#item difficulties. Just show the first 10 items difficulties
head(as.data.frame(mod1$xsi))
{% endhighlight %}



{% highlight text %}
##               xsi     se.xsi
## Math.1 -1.1901775 0.06170396
## Math.2 -0.5384382 0.05552351
## Math.3  0.2070387 0.05424712
## Math.4  0.7624491 0.05714235
## Math.5  0.8450950 0.05786723
## Math.6 -0.1907538 0.05419563
{% endhighlight %}



{% highlight r %}
#view the range of fit statistics, particularly infit
range(mod1fit$itemfit$Infit)
{% endhighlight %}



{% highlight text %}
## [1] 0.9596799 1.0292587
{% endhighlight %}



{% highlight r %}
#Get the sample size adjusted acceptable item fit range:
2* (2/sqrt(1500))
{% endhighlight %}



{% highlight text %}
## [1] 0.1032796
{% endhighlight %}
 
The smalles infit value is .96, the larges it 1.03. Therefore, items are fitting pretty well, though, a few wouldn't meet the acceptable standard based on certain fit criteria. 
 
This is all to say, we're good to start running our latent regressions. 
 
## 4. Latent Regression in Two Parts
Example Q1. Is there a noticable difference in general ability (based on the test we're analyzing) between groups who were in the treatment group (coded as 1) and those who were not (coded as 0)?
 
One of the advantages of the latent regression approach is that it gets you item and student level information, potentially, and takes measurement error into account. If you were to simply regress test total score on the group identifier, you would have no measurement error. Plus, this regression approach wouldn't really be a latent variable model. It takes the observed score and regresses it on the observed student classification.  
  
    
 
### Part I. Two Ways to Analyze Group Differences in TAM
Treat the "treat" variable as placing students in groups, 1 and 0. We can do this two ways in TAM.
 
Formula for latent regression: 
$$\theta = \beta_1*X_1 + \epsilon$$ 
where $$\beta_1$$ is the regression coefficient for 1. $$X_1$$ takes on a value of 1 if the student is in the treatment group. Error is basically person specific (though, drawn from a normal distribution).
 
With a dichotomous treatment variable, there are a few ways to do this in TAM. The first treats the data as if it comes from two "groups." This method gets us group variances. So for instance, we can not only see if the two groups have major differeces via their theta estimates, we can see if their underlying distributions have different "shapes"






















